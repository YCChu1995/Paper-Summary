# BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
> [1810.04805](https://arxiv.org/abs/1810.04805)<br>
> BERT
<div align=center><img src="/figures/1810.04805.1.png" style="height: 150px; width: auto;"/></div>

## Summary 
1. 

## Tech Insights 
1. 

---

## Motivation 
1. 

## Experiment
### 1.
### 2. 
- x
- y<br>
&rarr; y1 + y2 = y3
- z
